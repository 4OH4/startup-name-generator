{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, SimpleRNN, GRU, TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "- Set 'behemoth' as a variable name here\n",
    "- Save the 500epoch behemoth RNN as an intermediate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wretched\\n', 'blow\\n', 'extinguish\\n', 'congregation\\n', 'spirits\\n']\n"
     ]
    }
   ],
   "source": [
    "from preprocess import text_to_words\n",
    "\n",
    "# Generate a list of words (including newline)\n",
    "textfile = \"wordlists/behemoth.txt\"\n",
    "words = text_to_words(textfile)\n",
    "\n",
    "print(words[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755 words\n",
      "\n",
      "vocabulary of 27 characters, including the \\n:\n",
      "['\\n', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "First two sample words:\n",
      "['wretched\\n', 'blow\\n']\n"
     ]
    }
   ],
   "source": [
    "# Generate the set of unique characters (including newline)\n",
    "# https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python\n",
    "chars = sorted(list(set([char for word in words for char in word])))\n",
    "\n",
    "VOCAB_SIZE = len(chars)\n",
    "N_WORDS = len(words)\n",
    "MAX_WORD_LEN = 12  # maximum company name length\n",
    "\n",
    "\n",
    "print(N_WORDS, \"words\\n\")\n",
    "print(\"vocabulary of\", len(chars), \"characters, including the \\\\n:\")\n",
    "print(chars)\n",
    "print(\"\\nFirst two sample words:\")\n",
    "print(words[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_char = {ix:char for ix, char in enumerate(chars)}\n",
    "char_to_ix = {char:ix for ix, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((N_WORDS, MAX_WORD_LEN, VOCAB_SIZE))\n",
    "Y = np.zeros((N_WORDS, MAX_WORD_LEN, VOCAB_SIZE))\n",
    "\n",
    "for word_i in range(N_WORDS):\n",
    "    word = words[word_i]\n",
    "    chars = list(word)\n",
    "    word_len = len(word)\n",
    "    \n",
    "    for char_j in range(min(len(word), MAX_WORD_LEN)):\n",
    "        char = chars[char_j]\n",
    "        char_ix = char_to_ix[char]\n",
    "        X[word_i, char_j, char_ix] = 1\n",
    "        if char_j > 0:\n",
    "            Y[word_i, char_j - 1, char_ix] = 1  # the 'next char' at time point char_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_NUM = 1\n",
    "HIDDEN_DIM = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "#model.add(SimpleRNN(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "#for i in range(LAYER_NUM - 1):\n",
    "#    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, None, 50)          15600     \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 27)          1377      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, None, 27)          0         \n",
      "=================================================================\n",
      "Total params: 16,977\n",
      "Trainable params: 16,977\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_scale(probs, temperature = 1.0):\n",
    "    # a low temperature (< 1 and approaching 0) results in the char sampling approaching the argmax.\n",
    "    # a high temperature (> 1, approaching infinity) results in sampling from a uniform distribution)\n",
    "    probs = np.exp(np.log(probs) / temperature)\n",
    "    probs = probs / np.sum(probs)\n",
    "    return probs\n",
    "    \n",
    "    \n",
    "def generate_word(model, temperature = 1.0, min_word_length = 4):\n",
    "    X = np.zeros((1, MAX_WORD_LEN, VOCAB_SIZE))\n",
    "    \n",
    "    # sample the first character\n",
    "    initial_char_distribution = temp_scale(model.predict(X[:, 0:1, :]).flatten(), temperature)\n",
    "    \n",
    "    ix = 0\n",
    "    while ix == 0:  # make sure the initial character is not a newline (i.e. index 0)\n",
    "        ix = int(np.random.choice(VOCAB_SIZE, size = 1, p = initial_char_distribution))\n",
    "    \n",
    "    X[0, 0, ix] = 1\n",
    "    generated_word = [ix_to_char[ix].upper()]  # start with first character, then later successively append chars\n",
    "    \n",
    "    # sample all remaining characters\n",
    "    for i in range(1, MAX_WORD_LEN):\n",
    "        next_char_distribution = temp_scale(model.predict(X[:, 0:i, :])[:, i-1, :].flatten(), temperature)\n",
    "\n",
    "        \n",
    "        ix_choice = np.random.choice(VOCAB_SIZE, size = 1, p = next_char_distribution)\n",
    "        # ix_choice = np.argmax(next_char_distribution)  # <- corresponds to sampling with a very low temperature\n",
    "        ctr = 0\n",
    "        while ix_choice == 0 and i < min_word_length:\n",
    "            ctr += 1\n",
    "            # sample again if you picked the end-of-word token too early\n",
    "            ix_choice = np.random.choice(VOCAB_SIZE, size = 1, p = next_char_distribution)\n",
    "            if ctr > 1000:\n",
    "                print(\"caught in a near-infinite loop. You might have picked too low a temperature and the sampler just keeps sampling \\\\n's\")\n",
    "                break\n",
    "            \n",
    "        \n",
    "        next_ix = int(ix_choice)\n",
    "        X[0, i, next_ix] = 1\n",
    "        if next_ix == 0:\n",
    "            break\n",
    "        generated_word.append(ix_to_char[next_ix])\n",
    "    \n",
    "    return ('').join(generated_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50: Nzist\n",
      "epoch 100: Vaind\n",
      "epoch 150: Seree\n",
      "epoch 200: Sstonube\n",
      "epoch 250: Ithurnide\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 250\n",
    "BATCH_SIZE = 64  # or: N_WORDS\n",
    "\n",
    "epoch = 0\n",
    "while epoch < NUM_EPOCHS:\n",
    "    model.fit(X, Y, batch_size=BATCH_SIZE, verbose=0, epochs=1)\n",
    "    epoch += 1\n",
    "    \n",
    "    # if epoch % 100 == 0:\n",
    "    #     print(\"epoch\", epoch)\n",
    "    \n",
    "    # print a word every few epochs to watch the algorithm learn\n",
    "    if epoch % 50 == 0:\n",
    "        print(\"epoch \" + str(epoch) + \": \" + generate_word(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ether\n",
      "Hount\n",
      "Over\n",
      "Raipt\n",
      "Tirse\n",
      "Omos\n",
      "Ares\n",
      "Marie\n",
      "Unturiy\n",
      "Orned\n",
      "Exorrs\n",
      "Aned\n",
      "Apale\n",
      "Enaime\n",
      "Ovience\n",
      "Ubloutins\n",
      "Ustore\n",
      "Inestirgat\n",
      "Oushed\n",
      "Igneceneia\n",
      "Ored\n",
      "Ught\n",
      "Hark\n",
      "Gort\n",
      "Rops\n",
      "Astracth\n",
      "Underk\n",
      "Rais\n",
      "Igntining\n",
      "Iath\n"
     ]
    }
   ],
   "source": [
    "# Print a few words with the final model:\n",
    "\n",
    "for _ in range(30):\n",
    "    print(generate_word(model, temperature = 0.8, min_word_length = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- Go to codementor.io and have an expert review your code, e.g. from [this guy](https://www.codementor.io/mepstein68)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
