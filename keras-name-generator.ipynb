{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chunml.github.io/ChunML.github.io/project/Creating-Text-Generator-Using-Recurrent-Neural-Network/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, SimpleRNN, GRU, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary of 26 characters, including the \\n:\n",
      "['\\n', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y']\n",
      "\n",
      "First two sample words:\n",
      "['aballacos\\n', 'abalna\\n']\n"
     ]
    }
   ],
   "source": [
    "# Generate a list of words (including newline)\n",
    "wordlist = \"wordlists/gallic.txt\"\n",
    "words = [x.lower() for x in open(wordlist)]\n",
    "\n",
    "# Generate the set of unique characters (including newline)\n",
    "# https://stackoverflow.com/questions/952914/making-a-flat-list-out-of-list-of-lists-in-python\n",
    "chars = sorted(list(set([char for word in words for char in word])))\n",
    "\n",
    "VOCAB_SIZE = len(chars)\n",
    "N_WORDS = len(words)\n",
    "MAX_WORD_LEN = 12  # maximum company name length\n",
    "\n",
    "print(\"vocabulary of\", len(chars), \"characters, including the \\\\n:\")\n",
    "print(chars)\n",
    "print(\"\\nFirst two sample words:\")\n",
    "print(words[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_to_char = {ix:char for ix, char in enumerate(chars)}\n",
    "char_to_ix = {char:ix for ix, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((N_WORDS, MAX_WORD_LEN, VOCAB_SIZE))\n",
    "Y = np.zeros((N_WORDS, MAX_WORD_LEN, VOCAB_SIZE))\n",
    "\n",
    "for word_i in range(N_WORDS):\n",
    "    word = words[word_i]\n",
    "    chars = list(word)\n",
    "    word_len = len(word)\n",
    "    \n",
    "    for char_j in range(min(len(word), MAX_WORD_LEN)):\n",
    "        char = chars[char_j]\n",
    "        char_ix = char_to_ix[char]\n",
    "        X[word_i, char_j, char_ix] = 1\n",
    "        if char_j > 0:\n",
    "            Y[word_i, char_j - 1, char_ix] = 1  # the 'next char' at time point char_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYER_NUM = 1\n",
    "HIDDEN_DIM = 50\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "model.add(SimpleRNN(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "#for i in range(LAYER_NUM - 1):\n",
    "#    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, None, 50)          3850      \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, None, 26)          1326      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 26)          0         \n",
      "=================================================================\n",
      "Total params: 5,176\n",
      "Trainable params: 5,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample the first character\n",
    "initial_char_distribution = model.predict(np.zeros((1, 1, VOCAB_SIZE))).flatten()\n",
    "ix = 0\n",
    "while ix == 0:  # make sure the initial character is not a newline (i.e. index 0)\n",
    "    ix = int(np.random.choice(VOCAB_SIZE, size = 1, p = initial_char_distribution))\n",
    "\n",
    "generated_word = ix_to_char[ix]  # start with first character, then later successively append chars\n",
    "\n",
    "# sample all remaining characters\n",
    "for i in range(1, MAX_WORD_LEN):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model):\n",
    "    initial_char_distribution = model.predict(np.zeros((1, 1, VOCAB_SIZE))).flatten()\n",
    "    ix = np.random.choice(VOCAB_SIZE - 1, size = 1, p = initial_char_distribution[1:]) + 1  # leave out the index 0 (newline)\n",
    "    \n",
    "    y_char = ix_to_char[ix]\n",
    "    X = np.zeros((1, MAX_WORD_LEN, VOCAB_SIZE))\n",
    "    for i in range(MAX_WORD_LEN):\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "        if ix_to_char[ix[-1]] == \"\\n\":\n",
    "            break\n",
    "    print(\"\\n\", end=\"\")\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertos\n",
      "quatos\n",
      "uretos\n",
      "hertos\n",
      "dulos\n",
      "froganos\n",
      "quaregos\n",
      "ares\n",
      "xello\n",
      "gallos\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 500\n",
    "BATCH_SIZE = N_WORDS\n",
    "\n",
    "epoch = 0\n",
    "while epoch < NUM_EPOCHS:\n",
    "    model.fit(X, Y, batch_size=BATCH_SIZE, verbose=0, epochs=1)\n",
    "    epoch += 1\n",
    "    if epoch % 50 == 0:\n",
    "        generate_text(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00306856, 0.12435216, 0.01173217, 0.01435904, 0.01188214,\n",
       "       0.19284552, 0.00098659, 0.00843391, 0.00803371, 0.09215052,\n",
       "       0.00100746, 0.00470732, 0.05310497, 0.01440515, 0.03030822,\n",
       "       0.08553564, 0.02203017, 0.0015642 , 0.14398098, 0.01034166,\n",
       "       0.02304427, 0.11663546, 0.0073792 , 0.00188859, 0.01373165,\n",
       "       0.00249077], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_char_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  26, 1257,  116,  146,  112, 1918,   12,   83,   75,  905,    5,\n",
       "         72,  552,  128,  321,  878,  220,   18, 1439,   90,  234, 1135,\n",
       "         75,   20,  142,   21])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_char_distribution = model.predict(np.zeros((1, 1, VOCAB_SIZE))).flatten()\n",
    "initial_char_distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'length' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-24531bc4273c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-e535f6405fe9>\u001b[0m in \u001b[0;36mgenerate_text\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my_char\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mix_to_char\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'length' is not defined"
     ]
    }
   ],
   "source": [
    "generate_text(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "\n",
    "- Experiment with different [temperatures](https://cs.stackexchange.com/questions/79241/what-is-temperature-in-lstm-and-neural-networks-generally)\n",
    "- Go to codementor.io and have an expert review your code, e.g. from [this guy](https://www.codementor.io/mepstein68)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
